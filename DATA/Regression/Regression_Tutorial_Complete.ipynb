{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Complete Regression Tutorial: Predicting Car Selling Price\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates a complete workflow for building a regression model to predict car selling prices.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 1: Import Libraries\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from sklearn.preprocessing import StandardScaler, LabelEncoder\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\\n\",\n",
    "    \"from sklearn.linear_model import LinearRegression, Ridge, Lasso\\n\",\n",
    "    \"from sklearn.ensemble import RandomForestRegressor\\n\",\n",
    "    \"from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\\n\",\n",
    "    \"import math\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set style for better visualizations\\n\",\n",
    "    \"sns.set_style('whitegrid')\\n\",\n",
    "    \"plt.rcParams['figure.figsize'] = (12, 6)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 2: Load and Explore Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load the car data\\n\",\n",
    "    \"df = pd.read_csv('/home/deven/PycharmProjects/Ml Tutorial/car data.csv')\\n\",\n",
    "    \"print(\\\"Dataset loaded successfully!\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nDataset shape: {df.shape}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Display first few rows\\n\",\n",
    "    \"print(\\\"First 10 rows:\\\")\\n\",\n",
    "    \"df.head(10)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Check data types and missing values\\n\",\n",
    "    \"print(\\\"Data Info:\\\")\\n\",\n",
    "    \"print(df.info())\\n\",\n",
    "    \"print(\\\"\\\\nMissing Values:\\\")\\n\",\n",
    "    \"print(df.isnull().sum())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Statistical summary\\n\",\n",
    "    \"print(\\\"Statistical Summary:\\\")\\n\",\n",
    "    \"df.describe()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Check unique values in categorical columns\\n\",\n",
    "    \"print(\\\"Unique values in categorical columns:\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nTransmission: {df['Transmission'].unique()}\\\")\\n\",\n",
    "    \"print(f\\\"Fuel_Type: {df['Fuel_Type'].unique()}\\\")\\n\",\n",
    "    \"print(f\\\"Seller_Type: {df['Seller_Type'].unique()}\\\")\\n\",\n",
    "    \"print(f\\\"Owner: {df['Owner'].unique()}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualize target variable distribution\\n\",\n",
    "    \"plt.figure(figsize=(10, 5))\\n\",\n",
    "    \"plt.subplot(1, 2, 1)\\n\",\n",
    "    \"plt.hist(df['Selling_Price'], bins=30, edgecolor='black', color='skyblue')\\n\",\n",
    "    \"plt.xlabel('Selling Price')\\n\",\n",
    "    \"plt.ylabel('Frequency')\\n\",\n",
    "    \"plt.title('Distribution of Selling Price')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.subplot(1, 2, 2)\\n\",\n",
    "    \"plt.boxplot(df['Selling_Price'])\\n\",\n",
    "    \"plt.ylabel('Selling Price')\\n\",\n",
    "    \"plt.title('Box Plot of Selling Price')\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Target Variable Statistics:\\\")\\n\",\n",
    "    \"print(f\\\"Mean: {df['Selling_Price'].mean():.2f}\\\")\\n\",\n",
    "    \"print(f\\\"Median: {df['Selling_Price'].median():.2f}\\\")\\n\",\n",
    "    \"print(f\\\"Std: {df['Selling_Price'].std():.2f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 3: Data Preprocessing\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create a copy for preprocessing\\n\",\n",
    "    \"df_processed = df.copy()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Drop Car_Name as it's just a label\\n\",\n",
    "    \"df_processed = df_processed.drop('Car_Name', axis=1)\\n\",\n",
    "    \"print(\\\"Dropped 'Car_Name' column\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Encode categorical variables\\n\",\n",
    "    \"le_transmission = LabelEncoder()\\n\",\n",
    "    \"df_processed['Transmission'] = le_transmission.fit_transform(df_processed['Transmission'])\\n\",\n",
    "    \"print(f\\\"Transmission encoding: Manual={le_transmission.transform(['Manual'])[0]}, Automatic={le_transmission.transform(['Automatic'])[0]}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"le_fuel = LabelEncoder()\\n\",\n",
    "    \"df_processed['Fuel_Type'] = le_fuel.fit_transform(df_processed['Fuel_Type'])\\n\",\n",
    "    \"print(f\\\"Fuel_Type encoding: {dict(zip(le_fuel.classes_, le_fuel.transform(le_fuel.classes_)))}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"le_seller = LabelEncoder()\\n\",\n",
    "    \"df_processed['Seller_Type'] = le_seller.fit_transform(df_processed['Seller_Type'])\\n\",\n",
    "    \"print(f\\\"Seller_Type encoding: {dict(zip(le_seller.classes_, le_seller.transform(le_seller.classes_)))}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nPreprocessed data:\\\")\\n\",\n",
    "    \"df_processed.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Separate features and target\\n\",\n",
    "    \"X = df_processed.drop('Selling_Price', axis=1)\\n\",\n",
    "    \"y = df_processed['Selling_Price']\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Features shape: {X.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Target shape: {y.shape}\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nFeature columns: {list(X.columns)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 4: Train-Test Split\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Split data: 80% train, 20% test\\n\",\n",
    "    \"X_train, X_test, y_train, y_test = train_test_split(\\n\",\n",
    "    \"    X, y, \\n\",\n",
    "    \"    test_size=0.2, \\n\",\n",
    "    \"    random_state=42\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Training set size: {X_train.shape[0]} samples\\\")\\n\",\n",
    "    \"print(f\\\"Test set size: {X_test.shape[0]} samples\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nTraining set shape: {X_train.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Test set shape: {X_test.shape}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 5: Feature Scaling\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Scale features\\n\",\n",
    "    \"scaler = StandardScaler()\\n\",\n",
    "    \"X_train_scaled = scaler.fit_transform(X_train)\\n\",\n",
    "    \"X_test_scaled = scaler.transform(X_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Convert to DataFrame for readability\\n\",\n",
    "    \"X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\\n\",\n",
    "    \"X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Scaling completed!\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nScaled training data (first 5 rows):\\\")\\n\",\n",
    "    \"X_train_scaled.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Show scaling effect\\n\",\n",
    "    \"print(\\\"Before Scaling (Original):\\\")\\n\",\n",
    "    \"print(X_train.describe().loc[['mean', 'std']].round(2))\\n\",\n",
    "    \"print(\\\"\\\\nAfter Scaling (Standardized):\\\")\\n\",\n",
    "    \"print(X_train_scaled.describe().loc[['mean', 'std']].round(2))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 6: Model Training - Linear Regression\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Train Linear Regression model\\n\",\n",
    "    \"lr_model = LinearRegression()\\n\",\n",
    "    \"lr_model.fit(X_train_scaled, y_train)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Linear Regression Model Trained!\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nIntercept: {lr_model.intercept_:.4f}\\\")\\n\",\n",
    "    \"print(\\\"\\\\nCoefficients for each feature:\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"coefficients_df = pd.DataFrame({\\n\",\n",
    "    \"    'Feature': X_train.columns,\\n\",\n",
    "    \"    'Coefficient': lr_model.coef_\\n\",\n",
    "    \"}).sort_values('Coefficient', ascending=False, key=abs)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(coefficients_df.to_string(index=False))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 7: Model Training - Alternative Models\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Train Ridge Regression\\n\",\n",
    "    \"ridge_model = Ridge(alpha=1.0)\\n\",\n",
    "    \"ridge_model.fit(X_train_scaled, y_train)\\n\",\n",
    "    \"print(\\\"Ridge Regression trained!\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Train Lasso Regression\\n\",\n",
    "    \"lasso_model = Lasso(alpha=0.01)\\n\",\n",
    "    \"lasso_model.fit(X_train_scaled, y_train)\\n\",\n",
    "    \"print(\\\"Lasso Regression trained!\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Train Random Forest\\n\",\n",
    "    \"rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\\n\",\n",
    "    \"rf_model.fit(X_train, y_train)  # No scaling needed for tree-based models\\n\",\n",
    "    \"print(\\\"Random Forest Regressor trained!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 8: Model Predictions\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Make predictions using Linear Regression\\n\",\n",
    "    \"y_pred_lr = lr_model.predict(X_test_scaled)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Show first 10 predictions vs actual\\n\",\n",
    "    \"comparison_df = pd.DataFrame({\\n\",\n",
    "    \"    'Actual': y_test.values[:10],\\n\",\n",
    "    \"    'Predicted': y_pred_lr[:10],\\n\",\n",
    "    \"    'Error': (y_test.values[:10] - y_pred_lr[:10]),\\n\",\n",
    "    \"    'Error %': abs((y_test.values[:10] - y_pred_lr[:10]) / y_test.values[:10] * 100)\\n\",\n",
    "    \"})\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"First 10 predictions (Linear Regression):\\\")\\n\",\n",
    "    \"print(comparison_df.round(4).to_string())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 9: Model Evaluation\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Function to calculate all evaluation metrics\\n\",\n",
    "    \"def evaluate_model(y_true, y_pred, model_name):\\n\",\n",
    "    \"    mae = mean_absolute_error(y_true, y_pred)\\n\",\n",
    "    \"    mse = mean_squared_error(y_true, y_pred)\\n\",\n",
    "    \"    rmse = math.sqrt(mse)\\n\",\n",
    "    \"    r2 = r2_score(y_true, y_pred)\\n\",\n",
    "    \"    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return {\\n\",\n",
    "    \"        'Model': model_name,\\n\",\n",
    "    \"        'MAE': mae,\\n\",\n",
    "    \"        'MSE': mse,\\n\",\n",
    "    \"        'RMSE': rmse,\\n\",\n",
    "    \"        'R² Score': r2,\\n\",\n",
    "    \"        'MAPE (%)': mape\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Evaluate Linear Regression\\n\",\n",
    "    \"lr_metrics = evaluate_model(y_test, y_pred_lr, 'Linear Regression')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nLinear Regression Evaluation:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\\n\",\n",
    "    \"for key, value in lr_metrics.items():\\n\",\n",
    "    \"    if key == 'Model':\\n\",\n",
    "    \"        print(f\\\"{key}: {value}\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(f\\\"{key}: {value:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Make predictions with other models\\n\",\n",
    "    \"y_pred_ridge = ridge_model.predict(X_test_scaled)\\n\",\n",
    "    \"y_pred_lasso = lasso_model.predict(X_test_scaled)\\n\",\n",
    "    \"y_pred_rf = rf_model.predict(X_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Evaluate all models\\n\",\n",
    "    \"ridge_metrics = evaluate_model(y_test, y_pred_ridge, 'Ridge')\\n\",\n",
    "    \"lasso_metrics = evaluate_model(y_test, y_pred_lasso, 'Lasso')\\n\",\n",
    "    \"rf_metrics = evaluate_model(y_test, y_pred_rf, 'Random Forest')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create comparison dataframe\\n\",\n",
    "    \"all_metrics = pd.DataFrame([\\n\",\n",
    "    \"    lr_metrics,\\n\",\n",
    "    \"    ridge_metrics,\\n\",\n",
    "    \"    lasso_metrics,\\n\",\n",
    "    \"    rf_metrics\\n\",\n",
    "    \"])\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*80)\\n\",\n",
    "    \"print(\\\"MODEL COMPARISON\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*80)\\n\",\n",
    "    \"print(all_metrics.round(4).to_string(index=False))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 10: Visualization - Model Performance\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Plot actual vs predicted\\n\",\n",
    "    \"fig, axes = plt.subplots(2, 2, figsize=(14, 10))\\n\",\n",
    "    \"\\n\",\n",
    "    \"models_data = [\\n\",\n",
    "    \"    (y_pred_lr, 'Linear Regression', axes[0, 0]),\\n\",\n",
    "    \"    (y_pred_ridge, 'Ridge', axes[0, 1]),\\n\",\n",
    "    \"    (y_pred_lasso, 'Lasso', axes[1, 0]),\\n\",\n",
    "    \"    (y_pred_rf, 'Random Forest', axes[1, 1])\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"for y_pred, title, ax in models_data:\\n\",\n",
    "    \"    ax.scatter(y_test, y_pred, alpha=0.6, color='blue')\\n\",\n",
    "    \"    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\\n\",\n",
    "    \"    ax.set_xlabel('Actual Selling Price', fontsize=10)\\n\",\n",
    "    \"    ax.set_ylabel('Predicted Selling Price', fontsize=10)\\n\",\n",
    "    \"    ax.set_title(f'{title}\\\\n(Actual vs Predicted)', fontsize=11, fontweight='bold')\\n\",\n",
    "    \"    ax.grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Plot residuals\\n\",\n",
    "    \"fig, axes = plt.subplots(2, 2, figsize=(14, 10))\\n\",\n",
    "    \"\\n\",\n",
    "    \"residuals_data = [\\n\",\n",
    "    \"    (y_test - y_pred_lr, 'Linear Regression', axes[0, 0]),\\n\",\n",
    "    \"    (y_test - y_pred_ridge, 'Ridge', axes[0, 1]),\\n\",\n",
    "    \"    (y_test - y_pred_lasso, 'Lasso', axes[1, 0]),\\n\",\n",
    "    \"    (y_test - y_pred_rf, 'Random Forest', axes[1, 1])\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"for residuals, title, ax in residuals_data:\\n\",\n",
    "    \"    ax.scatter(y_pred_lr[:len(residuals)], residuals, alpha=0.6, color='green')\\n\",\n",
    "    \"    ax.axhline(y=0, color='r', linestyle='--', lw=2)\\n\",\n",
    "    \"    ax.set_xlabel('Predicted Values', fontsize=10)\\n\",\n",
    "    \"    ax.set_ylabel('Residuals', fontsize=10)\\n\",\n",
    "    \"    ax.set_title(f'{title} - Residual Plot', fontsize=11, fontweight='bold')\\n\",\n",
    "    \"    ax.grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Feature Importance from Random Forest\\n\",\n",
    "    \"feature_importance = pd.DataFrame({\\n\",\n",
    "    \"    'Feature': X_train.columns,\\n\",\n",
    "    \"    'Importance': rf_model.feature_importances_\\n\",\n",
    "    \"}).sort_values('Importance', ascending=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(10, 6))\\n\",\n",
    "    \"plt.barh(feature_importance['Feature'], feature_importance['Importance'], color='steelblue')\\n\",\n",
    "    \"plt.xlabel('Importance Score', fontsize=12)\\n\",\n",
    "    \"plt.ylabel('Feature', fontsize=12)\\n\",\n",
    "    \"plt.title('Random Forest - Feature Importance', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nFeature Importance Ranking:\\\")\\n\",\n",
    "    \"print(feature_importance.to_string(index=False))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 11: Distribution of Residuals\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Distribution of residuals for Linear Regression\\n\",\n",
    "    \"residuals = y_test - y_pred_lr\\n\",\n",
    "    \"\\n\",\n",
    "    \"fig, axes = plt.subplots(1, 2, figsize=(14, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Histogram\\n\",\n",
    "    \"axes[0].hist(residuals, bins=20, edgecolor='black', color='orange', alpha=0.7)\\n\",\n",
    "    \"axes[0].axvline(x=0, color='red', linestyle='--', linewidth=2)\\n\",\n",
    "    \"axes[0].set_xlabel('Residuals', fontsize=12)\\n\",\n",
    "    \"axes[0].set_ylabel('Frequency', fontsize=12)\\n\",\n",
    "    \"axes[0].set_title('Distribution of Residuals (Linear Regression)', fontsize=12, fontweight='bold')\\n\",\n",
    "    \"axes[0].grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Q-Q Plot\\n\",\n",
    "    \"from scipy import stats\\n\",\n",
    "    \"stats.probplot(residuals, dist=\\\"norm\\\", plot=axes[1])\\n\",\n",
    "    \"axes[1].set_title('Q-Q Plot (Linear Regression)', fontsize=12, fontweight='bold')\\n\",\n",
    "    \"axes[1].grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Residuals Statistics:\\\")\\n\",\n",
    "    \"print(f\\\"Mean: {residuals.mean():.4f}\\\")\\n\",\n",
    "    \"print(f\\\"Std: {residuals.std():.4f}\\\")\\n\",\n",
    "    \"print(f\\\"Min: {residuals.min():.4f}\\\")\\n\",\n",
    "    \"print(f\\\"Max: {residuals.max():.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 12: Model Comparison - Visualization\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Compare R² scores\\n\",\n",
    "    \"fig, axes = plt.subplots(1, 2, figsize=(14, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# R² Score comparison\\n\",\n",
    "    \"r2_scores = all_metrics.set_index('Model')['R² Score']\\n\",\n",
    "    \"colors = ['green' if score == r2_scores.max() else 'steelblue' for score in r2_scores]\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[0].bar(r2_scores.index, r2_scores.values, color=colors, alpha=0.7, edgecolor='black')\\n\",\n",
    "    \"axes[0].set_ylabel('R² Score', fontsize=12)\\n\",\n",
    "    \"axes[0].set_title('Model Comparison - R² Score', fontsize=12, fontweight='bold')\\n\",\n",
    "    \"axes[0].set_ylim(0, 1)\\n\",\n",
    "    \"axes[0].grid(True, alpha=0.3, axis='y')\\n\",\n",
    "    \"for i, v in enumerate(r2_scores.values):\\n\",\n",
    "    \"    axes[0].text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# RMSE comparison\\n\",\n",
    "    \"rmse_scores = all_metrics.set_index('Model')['RMSE']\\n\",\n",
    "    \"colors = ['green' if score == rmse_scores.min() else 'coral' for score in rmse_scores]\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[1].bar(rmse_scores.index, rmse_scores.values, color=colors, alpha=0.7, edgecolor='black')\\n\",\n",
    "    \"axes[1].set_ylabel('RMSE', fontsize=12)\\n\",\n",
    "    \"axes[1].set_title('Model Comparison - RMSE (Lower is Better)', fontsize=12, fontweight='bold')\\n\",\n",
    "    \"axes[1].grid(True, alpha=0.3, axis='y')\\n\",\n",
    "    \"for i, v in enumerate(rmse_scores.values):\\n\",\n",
    "    \"    axes[1].text(i, v + 0.05, f'{v:.3f}', ha='center', fontweight='bold')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 13: Hyperparameter Tuning (Optional)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Grid Search for Ridge Regression\\n\",\n",
    "    \"print(\\\"Performing Grid Search for Ridge Regression...\\\")\\n\",\n",
    "    \"print(\\\"This may take a moment...\\\\n\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"param_grid = {\\n\",\n",
    "    \"    'alpha': [0.001, 0.01, 0.1, 1, 10, 100]\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"grid_search = GridSearchCV(\\n\",\n",
    "    \"    Ridge(), \\n\",\n",
    "    \"    param_grid, \\n\",\n",
    "    \"    cv=5,\\n\",\n",
    "    \"    scoring='r2',\\n\",\n",
    "    \"    n_jobs=-1\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"grid_search.fit(X_train_scaled, y_train)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Best parameters: {grid_search.best_params_}\\\")\\n\",\n",
    "    \"print(f\\\"Best CV R² Score: {grid_search.best_score_:.4f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Get results dataframe\\n\",\n",
    "    \"cv_results_df = pd.DataFrame(grid_search.cv_results_)\\n\",\n",
    "    \"cv_results_df = cv_results_df[['param_alpha', 'mean_test_score', 'std_test_score']]\\n\",\n",
    "    \"cv_results_df.columns = ['Alpha', 'Mean CV Score', 'Std CV Score']\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nCross-Validation Results:\\\")\\n\",\n",
    "    \"print(cv_results_df.to_string(index=False))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Plot grid search results\\n\",\n",
    "    \"plt.figure(figsize=(10, 6))\\n\",\n",
    "    \"alphas = cv_results_df['Alpha'].values\\n\",\n",
    "    \"scores = cv_results_df['Mean CV Score'].values\\n\",\n",
    "    \"std = cv_results_df['Std CV Score'].values\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.errorbar(alphas, scores, yerr=std, marker='o', markersize=8, capsize=5, capthick=2)\\n\",\n",
    "    \"plt.xlabel('Alpha', fontsize=12)\\n\",\n",
    "    \"plt.ylabel('Cross-Validation R² Score', fontsize=12)\\n\",\n",
    "    \"plt.title('Grid Search Results - Ridge Regression', fontsize=12, fontweight='bold')\\n\",\n",
    "    \"plt.xscale('log')\\n\",\n",
    "    \"plt.grid(True, alpha=0.3)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 14: Predictions on New Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create sample new cars for prediction\\n\",\n",
    "    \"new_cars = pd.DataFrame({\\n\",\n",
    "    \"    'Year': [2020, 2019, 2018],\\n\",\n",
    "    \"    'Present_Price': [10.5, 8.2, 7.3],\\n\",\n",
    "    \"    'Kms_Driven': [50000, 75000, 100000],\\n\",\n",
    "    \"    'Fuel_Type': [0, 1, 0],\\n\",\n",
    "    \"    'Seller_Type': [0, 1, 0],\\n\",\n",
    "    \"    'Transmission': [0, 0, 1],\\n\",\n",
    "    \"    'Owner': [0, 0, 1]\\n\",\n",
    "    \"})\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"New Cars Data:\\\")\\n\",\n",
    "    \"print(new_cars)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Scale new data using same scaler\\n\",\n",
    "    \"new_cars_scaled = scaler.transform(new_cars)\\n\",\n",
    "    \"new_cars_scaled = pd.DataFrame(new_cars_scaled, columns=new_cars.columns)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Make predictions with best model (Random Forest)\\n\",\n",
    "    \"predicted_prices = rf_model.predict(new_cars)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Display predictions\\n\",\n",
    "    \"results = pd.DataFrame({\\n\",\n",
    "    \"    'Year': new_cars['Year'],\\n\",\n",
    "    \"    'Present_Price': new_cars['Present_Price'],\\n\",\n",
    "    \"    'Predicted_Selling_Price': predicted_prices\\n\",\n",
    "    \"})\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nPredictions (Using Random Forest Model):\\\")\\n\",\n",
    "    \"print(results.to_string(index=False))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Step 15: Summary and Best Model Selection\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Display final summary\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*80)\\n\",\n",
    "    \"print(\\\"FINAL MODEL COMPARISON SUMMARY\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*80)\\n\",\n",
    "    \"\\n\",\n",
    "    \"summary_df = all_metrics.copy()\\n\",\n",
    "    \"summary_df = summary_df.round(4)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(summary_df.to_string(index=False))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Find best model\\n\",\n",
    "    \"best_model_name = all_metrics.loc[all_metrics['R² Score'].idxmax(), 'Model']\\n\",\n",
    "    \"best_r2 = all_metrics['R² Score'].max()\\n\",\n",
    "    \"best_rmse = all_metrics[all_metrics['Model'] == best_model_name]['RMSE'].values[0]\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*80)\\n\",\n",
    "    \"print(f\\\"BEST MODEL: {best_model_name}\\\")\\n\",\n",
    "    \"print(f\\\"R² Score: {best_r2:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"RMSE: {best_rmse:.4f}\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*80)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nInterpretation:\\\")\\n\",\n",
    "    \"print(f\\\"- The {best_model_name} model explains {best_r2*100:.2f}% of the variance in selling prices.\\\")\\n\",\n",
    "    \"print(f\\\"- On average, predictions are off by ±{best_rmse:.4f} (in price units).\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Conclusion\\n\",\n",
    "    \"\\n\",\n",
    "    \"This tutorial demonstrated a complete machine learning workflow:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **Data Loading & Exploration** - Understanding the dataset\\n\",\n",
    "    \"2. **Preprocessing** - Cleaning and encoding categorical variables\\n\",\n",
    "    \"3. **Train-Test Split** - Dividing data for proper evaluation\\n\",\n",
    "    \"4. **Feature Scaling** - Normalizing features for linear models\\n\",\n",
    "    \"5. **Model Training** - Training multiple regression models\\n\",\n",
    "    \"6. **Evaluation** - Comparing model performance using various metrics\\n\",\n",
    "    \"7. **Visualization** - Creating insightful plots\\n\",\n",
    "    \"8. **Hyperparameter Tuning** - Optimizing model parameters\\n\",\n",
    "    \"9. **Predictions** - Making predictions on new data\\n\",\n",
    "    \"\\n\",\n",
    "    \"The key to building good models is iterating on these steps and constantly evaluating your results!\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}\n"
   ],
   "id": "448864dbc5849e86"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
